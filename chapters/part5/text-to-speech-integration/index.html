<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Chapter 19: Text-to-Speech Integration</title>
  <meta name="description" content="“I need to create voice-driven experiences with background music and sound effects, but integrating separate systems is causing sync issues and inconsistent ...">
  <link rel="canonical" href="https://scttfrdmn.github.io/practical-meta-audiocraft/chapters/part5/text-to-speech-integration/">
  
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      line-height: 1.6;
      color: #333;
      margin: 0;
      padding: 0;
    }
    .wrapper {
      max-width: 100%;
    }
    .container {
      max-width: 960px;
      margin: 0 auto;
      padding: 0 20px;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 2rem;
      margin-bottom: 1rem;
    }
    h1 { color: #1a73e8; }
    h2 { color: #34a853; }
    a {
      color: #1a73e8;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .site-header {
      border-bottom: 1px solid #eee;
      padding: 15px 0;
      margin-bottom: 30px;
    }
    .site-title {
      margin: 0;
      font-size: 1.8rem;
    }
    .site-title a {
      color: #1a73e8;
      text-decoration: none;
    }
    .site-nav {
      float: right;
      margin-top: 10px;
    }
    .site-nav .page-link {
      margin-left: 20px;
    }
    .nav-trigger {
      display: none;
    }
    .menu-icon {
      display: none;
    }
    .page-content {
      padding: 20px 0;
    }
    .site-footer {
      border-top: 1px solid #eee;
      padding: 30px 0;
      margin-top: 60px;
    }
    .footer-col-wrapper {
      display: flex;
      flex-wrap: wrap;
    }
    .footer-col {
      flex: 1;
      min-width: 200px;
      padding-right: 20px;
    }
    code {
      background-color: #f5f5f5;
      padding: 2px 5px;
      border-radius: 3px;
    }
    pre {
      background-color: #f5f5f5;
      padding: 15px;
      border-radius: 5px;
      overflow-x: auto;
    }
    .highlight {
      background-color: #f5f5f5;
      border-radius: 5px;
    }
    table {
      border-collapse: collapse;
      width: 100%;
      margin-bottom: 20px;
    }
    th, td {
      border: 1px solid #ddd;
      padding: 8px 12px;
    }
    th {
      background-color: #f5f5f5;
      text-align: left;
    }
    button, .button {
      display: inline-block;
      background-color: #1a73e8;
      color: white !important;
      padding: 10px 20px;
      border-radius: 4px;
      font-weight: bold;
      margin-top: 20px;
      border: none;
      cursor: pointer;
      text-decoration: none !important;
    }
    button:hover, .button:hover {
      background-color: #0d65d9;
    }
    .feature {
      background-color: #f5f5f5;
      border-radius: 8px;
      padding: 20px;
      border-left: 4px solid #1a73e8;
      margin-bottom: 20px;
    }
    
    @media screen and (max-width: 600px) {
      .site-nav {
        position: absolute;
        top: 70px;
        right: 20px;
        background-color: white;
        border: 1px solid #ddd;
        border-radius: 5px;
        text-align: right;
        padding: 0;
        z-index: 1;
      }
      .site-nav .page-link {
        display: block;
        padding: 10px;
        margin: 0;
      }
      .site-nav .menu-icon {
        display: block;
        float: right;
        width: 36px;
        height: 26px;
        line-height: 0;
        padding-top: 10px;
        text-align: center;
      }
      .site-nav .trigger {
        clear: both;
        display: none;
      }
      .site-nav input:checked ~ .trigger {
        display: block;
        padding-bottom: 5px;
      }
      .footer-col-wrapper {
        flex-direction: column;
      }
      .footer-col {
        margin-bottom: 20px;
      }
    }
  </style>
</head><body>
    <div class="wrapper">
      <header class="site-header">
        <div class="container">
          <h1 class="site-title"><a href="/practical-meta-audiocraft/">Practical Meta AudioCraft</a></h1>
          <nav class="site-nav">
            <input type="checkbox" id="nav-trigger" class="nav-trigger" />
            <label for="nav-trigger">
              <span class="menu-icon">
                <svg viewBox="0 0 18 15" width="18px" height="15px">
                  <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484c0-0.82,0.665-1.485,1.484-1.485 h15.032C17.335,0,18,0.665,18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516 c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,6.031,18,6.696,18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516c0-0.82,0.665-1.483,1.484-1.483h15.032 C17.335,12.031,18,12.696,18,13.516z"/>
                </svg>
              </span>
            </label>

            <div class="trigger">
              <a class="page-link" href="/practical-meta-audiocraft/">Home</a>
              <a class="page-link" href="/practical-meta-audiocraft/chapters/part1/introduction/">Getting Started</a>
              <a class="page-link" href="/practical-meta-audiocraft/chapters/part2/basic-music/">MusicGen</a>
              <a class="page-link" href="/practical-meta-audiocraft/chapters/part3/introduction-to-audiogen/">AudioGen</a>
              <a class="page-link" href="/practical-meta-audiocraft/tutorials/getting-started/">Tutorials</a>
            </div>
          </nav>
        </div>
      </header>

      <main class="page-content" aria-label="Content">
        <div class="container">
          <div class="chapter">
  <div class="chapter-header">
    <div class="chapter-metadata">
      <span class="difficulty advanced">Advanced</span>
      <span class="estimated-time">3 hours</span>
    </div>
    <h1>Chapter 19: Text-to-Speech Integration</h1>
  </div>
  
  
  
  <blockquote>
  <p>“I need to create voice-driven experiences with background music and sound effects, but integrating separate systems is causing sync issues and inconsistent quality. I’m spending too much time manually assembling audio components instead of focusing on content.” — <em>Maya Rodriguez, Interactive Media Producer</em></p>
</blockquote>

<h1 id="chapter-19-text-to-speech-integration">Chapter 19: Text-to-Speech Integration</h1>

<h2 id="the-challenge">The Challenge</h2>

<p>While AudioCraft excels at generating music and environmental sounds, it doesn’t natively handle voice synthesis. Yet many practical applications—from interactive experiences to educational content—require a combination of spoken narration, background music, and sound effects. Developers and content creators typically end up cobbling together multiple disconnected systems, resulting in workflow inefficiencies, synchronization problems, and inconsistent audio quality.</p>

<p>The ideal solution integrates high-quality Text-to-Speech (TTS) capabilities with AudioCraft’s generative audio systems within a unified framework that handles timing, mixing, and production automatically. This integration should preserve the expressive capabilities of modern TTS systems while leveraging AudioCraft’s strengths in creating rich environmental sounds and music.</p>

<p>In this chapter, you’ll learn how to build a complete integrated audio narrative pipeline that combines advanced TTS systems with AudioCraft models. We’ll show you how to select the right TTS technology for your needs, synchronize audio elements with precision, and create production-ready audio experiences that blend voice, music, and sound effects seamlessly.</p>

<h2 id="learning-objectives">Learning Objectives</h2>

<p>By the end of this chapter, you’ll be able to:</p>

<ul>
  <li>Evaluate and implement different TTS systems based on their strengths and compatibility with AudioCraft</li>
  <li>Design a unified pipeline that integrates TTS with music and sound effect generation</li>
  <li>Synchronize voice narration with background elements using automated timeline management</li>
  <li>Control emotion, pacing, and style in voice narration to complement generated audio</li>
  <li>Create complete audio narratives with professional quality mixing and mastering</li>
</ul>

<h2 id="prerequisites">Prerequisites</h2>

<p>Before proceeding, ensure you have:</p>
<ul>
  <li>Completed the chapters on basic MusicGen and AudioGen usage</li>
  <li>Completed Chapter 18 on building a complete audio pipeline</li>
  <li>Understanding of audio processing concepts (sample rates, mixing, normalization)</li>
  <li>Familiarity with Python and API integration</li>
</ul>

<h2 id="key-concepts">Key Concepts</h2>

<h3 id="modern-tts-technologies">Modern TTS Technologies</h3>

<p>Text-to-Speech has evolved dramatically in recent years, moving from robotic-sounding voices to highly natural speech synthesis with emotional expression. Modern TTS systems leverage deep learning to generate speech that’s increasingly difficult to distinguish from human recordings. These systems vary in their approach, capabilities, and integration requirements.</p>

<p>The ideal TTS system for AudioCraft integration should provide:</p>
<ol>
  <li>High-quality, natural-sounding voices</li>
  <li>Emotional expression and prosody control</li>
  <li>Reasonable generation speed</li>
  <li>Straightforward API or local integration</li>
  <li>Voice variety or voice cloning capabilities</li>
</ol>

<p>Several TTS systems meet these criteria to varying degrees. Bark by Suno AI offers exceptional expressivity through its innovative prompt format. ElevenLabs provides industry-leading voice quality with fine-grained control. XTTS/YourTTS offers voice cloning with multilingual support. Tortoise TTS provides high-quality results with open architecture, and Facebook’s MMS offers integration potential with other Meta AI tools.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Conceptual comparison of TTS systems
</span><span class="n">tts_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"Bark"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"quality"</span><span class="p">:</span> <span class="s">"Very Good"</span><span class="p">,</span>
        <span class="s">"expressivity"</span><span class="p">:</span> <span class="s">"Excellent"</span><span class="p">,</span>
        <span class="s">"speed"</span><span class="p">:</span> <span class="s">"Moderate"</span><span class="p">,</span>
        <span class="s">"integration"</span><span class="p">:</span> <span class="s">"Local (pip install)"</span><span class="p">,</span>
        <span class="s">"voice_variety"</span><span class="p">:</span> <span class="s">"Good (prompt-based)"</span>
    <span class="p">},</span>
    <span class="s">"ElevenLabs"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"quality"</span><span class="p">:</span> <span class="s">"Excellent"</span><span class="p">,</span>
        <span class="s">"expressivity"</span><span class="p">:</span> <span class="s">"Very Good"</span><span class="p">,</span>
        <span class="s">"speed"</span><span class="p">:</span> <span class="s">"Fast (API)"</span><span class="p">,</span>
        <span class="s">"integration"</span><span class="p">:</span> <span class="s">"API only"</span><span class="p">,</span>
        <span class="s">"voice_variety"</span><span class="p">:</span> <span class="s">"Excellent (100+ voices + cloning)"</span>
    <span class="p">},</span>
    <span class="s">"XTTS/YourTTS"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"quality"</span><span class="p">:</span> <span class="s">"Good"</span><span class="p">,</span>
        <span class="s">"expressivity"</span><span class="p">:</span> <span class="s">"Moderate"</span><span class="p">,</span>
        <span class="s">"speed"</span><span class="p">:</span> <span class="s">"Moderate"</span><span class="p">,</span>
        <span class="s">"integration"</span><span class="p">:</span> <span class="s">"Local (pip install)"</span><span class="p">,</span>
        <span class="s">"voice_variety"</span><span class="p">:</span> <span class="s">"Good (cloning-based)"</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="audio-narrative-architecture">Audio Narrative Architecture</h3>

<p>An effective audio narrative architecture combines voice synthesis with background elements in a way that maintains synchronization, balances audio levels, and creates a cohesive listening experience. The architecture has several key components:</p>

<ol>
  <li><strong>Narrative Script</strong>: A structured representation of the audio experience, including voice content, timing information, and background elements</li>
  <li><strong>Voice Generation</strong>: Converting text to expressive speech</li>
  <li><strong>Background Generation</strong>: Creating music and environmental sounds</li>
  <li><strong>Timeline Management</strong>: Aligning all audio elements in time</li>
  <li><strong>Audio Mixing</strong>: Combining elements with appropriate levels and processing</li>
</ol>

<p>This architecture enables a declarative approach to creating audio narratives, where you specify what you want rather than manually executing each production step.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Conceptual example of a narrative script
</span><span class="n">narrative_script</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"voice"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"Welcome to our adventure"</span><span class="p">,</span> <span class="s">"emotion"</span><span class="p">:</span> <span class="s">"excited"</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
    <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"music"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Upbeat adventure music"</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">30.0</span><span class="p">},</span>
    <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"sfx"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Birds chirping"</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">3.0</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">10.0</span><span class="p">},</span>
    <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"voice"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"Listen to the birds!"</span><span class="p">,</span> <span class="s">"emotion"</span><span class="p">:</span> <span class="s">"happy"</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">},</span>
<span class="p">]</span>
</code></pre></div></div>

<h2 id="solution-walkthrough">Solution Walkthrough</h2>

<h3 id="1-setting-up-tts-integration">1. Setting Up TTS Integration</h3>

<p>Let’s begin by setting up a basic integration between Bark TTS and AudioCraft. Bark provides expressive voice synthesis and can be installed locally, making it a good starting point.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># tts_audiocraft_integration.py - Basic integration between Bark TTS and AudioCraft
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">import</span> <span class="nn">scipy.io.wavfile</span> <span class="k">as</span> <span class="n">wavfile</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">audiocraft.models</span> <span class="kn">import</span> <span class="n">MusicGen</span><span class="p">,</span> <span class="n">AudioGen</span>
<span class="kn">from</span> <span class="nn">audiocraft.data.audio</span> <span class="kn">import</span> <span class="n">audio_write</span>
<span class="kn">from</span> <span class="nn">bark</span> <span class="kn">import</span> <span class="n">SAMPLE_RATE</span><span class="p">,</span> <span class="n">generate_audio</span><span class="p">,</span> <span class="n">preload_models</span>

<span class="k">def</span> <span class="nf">setup_device</span><span class="p">():</span>
    <span class="s">"""Set up the appropriate device for AudioCraft models"""</span>
    <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s">"mps"</span>  <span class="c1"># Apple Silicon GPU
</span>        <span class="k">print</span><span class="p">(</span><span class="s">"Using MPS (Metal) for generation"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s">"cuda"</span>  <span class="c1"># NVIDIA GPU
</span>        <span class="k">print</span><span class="p">(</span><span class="s">"Using CUDA for generation"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s">"cpu"</span>  <span class="c1"># Fallback to CPU
</span>        <span class="k">print</span><span class="p">(</span><span class="s">"Using CPU for generation (this will be slow)"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">device</span>

<span class="k">def</span> <span class="nf">generate_voice</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"voice_output.wav"</span><span class="p">):</span>
    <span class="s">"""Generate speech using Bark TTS"""</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Generating voice narration: '</span><span class="si">{</span><span class="n">text</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span><span class="si">}</span><span class="s">...'"</span><span class="p">)</span>
    
    <span class="c1"># Generate speech using Bark
</span>    <span class="n">preload_models</span><span class="p">()</span>  <span class="c1"># Takes time on first run
</span>    <span class="n">speech_array</span> <span class="o">=</span> <span class="n">generate_audio</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Save as WAV file
</span>    <span class="n">wavfile</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span><span class="p">,</span> <span class="n">speech_array</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Voice saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">speech_array</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span>
</code></pre></div></div>

<h3 id="2-adding-music-and-sound-effect-generation">2. Adding Music and Sound Effect Generation</h3>

<p>Now, let’s add functions to generate background music and sound effects using AudioCraft models:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">generate_background_music</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"music_output.wav"</span><span class="p">):</span>
    <span class="s">"""Generate background music using MusicGen"""</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Generating background music: '</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
    
    <span class="c1"># Set up device
</span>    <span class="n">device</span> <span class="o">=</span> <span class="n">setup_device</span><span class="p">()</span>
    
    <span class="c1"># Load MusicGen model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">MusicGen</span><span class="p">.</span><span class="n">get_pretrained</span><span class="p">(</span><span class="s">'small'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Set generation parameters
</span>    <span class="n">model</span><span class="p">.</span><span class="n">set_generation_params</span><span class="p">(</span>
        <span class="n">duration</span><span class="o">=</span><span class="n">duration</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
        <span class="n">top_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Generate music
</span>    <span class="n">wav</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">([</span><span class="n">prompt</span><span class="p">])</span>
    
    <span class="c1"># Save the music
</span>    <span class="n">audio_write</span><span class="p">(</span>
        <span class="n">output_path</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'.wav'</span><span class="p">,</span> <span class="s">''</span><span class="p">),</span>
        <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">(),</span>
        <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="s">"loudness"</span>
    <span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Music saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span>

<span class="k">def</span> <span class="nf">generate_sound_effect</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"sfx_output.wav"</span><span class="p">):</span>
    <span class="s">"""Generate sound effect using AudioGen"""</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Generating sound effect: '</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
    
    <span class="c1"># Set up device
</span>    <span class="n">device</span> <span class="o">=</span> <span class="n">setup_device</span><span class="p">()</span>
    
    <span class="c1"># Load AudioGen model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">AudioGen</span><span class="p">.</span><span class="n">get_pretrained</span><span class="p">(</span><span class="s">'medium'</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    
    <span class="c1"># Set generation parameters
</span>    <span class="n">model</span><span class="p">.</span><span class="n">set_generation_params</span><span class="p">(</span>
        <span class="n">duration</span><span class="o">=</span><span class="n">duration</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
        <span class="n">top_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="c1"># Generate sound effect
</span>    <span class="n">wav</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">([</span><span class="n">prompt</span><span class="p">])</span>
    
    <span class="c1"># Save the sound effect
</span>    <span class="n">audio_write</span><span class="p">(</span>
        <span class="n">output_path</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'.wav'</span><span class="p">,</span> <span class="s">''</span><span class="p">),</span>
        <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">(),</span>
        <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="s">"loudness"</span>
    <span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Sound effect saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span>
</code></pre></div></div>

<h3 id="3-building-the-audio-mixing-system">3. Building the Audio Mixing System</h3>

<p>Next, we need a system to combine voice, music, and sound effects into a single cohesive audio file:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">combine_audio_tracks</span><span class="p">(</span><span class="n">voice_path</span><span class="p">,</span> <span class="n">music_path</span><span class="p">,</span> <span class="n">sfx_path</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"combined_output.wav"</span><span class="p">):</span>
    <span class="s">"""Combine voice, music, and optional sound effect into a single audio file"""</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Combining audio tracks..."</span><span class="p">)</span>
    
    <span class="c1"># Load the audio files
</span>    <span class="n">voice</span><span class="p">,</span> <span class="n">voice_sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">voice_path</span><span class="p">)</span>
    <span class="n">music</span><span class="p">,</span> <span class="n">music_sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">music_path</span><span class="p">)</span>
    
    <span class="c1"># Convert to mono if stereo
</span>    <span class="n">voice</span> <span class="o">=</span> <span class="n">voice</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">voice</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">voice</span>
    <span class="n">music</span> <span class="o">=</span> <span class="n">music</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">music</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">music</span>
    
    <span class="c1"># Resample to the same sample rate (use the voice sample rate)
</span>    <span class="k">if</span> <span class="n">music_sr</span> <span class="o">!=</span> <span class="n">voice_sr</span><span class="p">:</span>
        <span class="n">music</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">resample</span><span class="p">(</span><span class="n">music</span><span class="p">,</span> <span class="n">music_sr</span><span class="p">,</span> <span class="n">voice_sr</span><span class="p">)</span>
    
    <span class="c1"># Make all audio tracks the same length (use the voice length)
</span>    <span class="n">voice_length</span> <span class="o">=</span> <span class="n">voice</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># Trim or pad music
</span>    <span class="k">if</span> <span class="n">music</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">voice_length</span><span class="p">:</span>
        <span class="n">music</span> <span class="o">=</span> <span class="n">music</span><span class="p">[:</span><span class="n">voice_length</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">voice_length</span> <span class="o">-</span> <span class="n">music</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">music</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">music</span><span class="p">,</span> <span class="n">padding</span><span class="p">])</span>
    
    <span class="c1"># Initialize the combined audio with voice and music
</span>    <span class="n">voice_weight</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">music_weight</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># Adjust as needed
</span>    
    <span class="n">combined</span> <span class="o">=</span> <span class="p">(</span><span class="n">voice</span> <span class="o">*</span> <span class="n">voice_weight</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">music</span> <span class="o">*</span> <span class="n">music_weight</span><span class="p">)</span>
    
    <span class="c1"># Add sound effects if provided
</span>    <span class="k">if</span> <span class="n">sfx_path</span><span class="p">:</span>
        <span class="n">sfx</span><span class="p">,</span> <span class="n">sfx_sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">sfx_path</span><span class="p">)</span>
        <span class="n">sfx</span> <span class="o">=</span> <span class="n">sfx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">sfx</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">sfx</span>
        
        <span class="k">if</span> <span class="n">sfx_sr</span> <span class="o">!=</span> <span class="n">voice_sr</span><span class="p">:</span>
            <span class="n">sfx</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">resample</span><span class="p">(</span><span class="n">sfx</span><span class="p">,</span> <span class="n">sfx_sr</span><span class="p">,</span> <span class="n">voice_sr</span><span class="p">)</span>
        
        <span class="c1"># Trim or pad sfx
</span>        <span class="k">if</span> <span class="n">sfx</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">voice_length</span><span class="p">:</span>
            <span class="n">sfx</span> <span class="o">=</span> <span class="n">sfx</span><span class="p">[:</span><span class="n">voice_length</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">voice_length</span> <span class="o">-</span> <span class="n">sfx</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">sfx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">sfx</span><span class="p">,</span> <span class="n">padding</span><span class="p">])</span>
        
        <span class="c1"># Add to the mix
</span>        <span class="n">sfx_weight</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Adjust as needed
</span>        <span class="n">combined</span> <span class="o">=</span> <span class="n">combined</span> <span class="o">+</span> <span class="p">(</span><span class="n">sfx</span> <span class="o">*</span> <span class="n">sfx_weight</span><span class="p">)</span>
    
    <span class="c1"># Normalize to prevent clipping
</span>    <span class="n">max_val</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">combined</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">max_val</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="n">combined</span> <span class="o">/</span> <span class="n">max_val</span>
    
    <span class="c1"># Save the combined audio
</span>    <span class="n">torchaudio</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">combined</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">voice_sr</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Combined audio saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output_path</span>
</code></pre></div></div>

<h3 id="4-creating-an-integrated-narrative-pipeline">4. Creating an Integrated Narrative Pipeline</h3>

<p>Finally, let’s integrate everything into a timeline-based narrative pipeline that can handle a script with precise timing:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_timed_audio_experience</span><span class="p">(</span><span class="n">script</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"timed_output.wav"</span><span class="p">):</span>
    <span class="s">"""
    Creates a synchronized audio experience from a timed script
    
    Script format:
    [
        {"type": "voice", "text": "Welcome to the jungle", "start_time": 0.0},
        {"type": "sfx", "description": "jungle ambience", "start_time": 0.5, "duration": 10.0},
        {"type": "music", "description": "tribal drums", "start_time": 2.0, "duration": 8.0}
    ]
    """</span>
    <span class="c1"># Sort script by start time
</span>    <span class="n">script</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">])</span>
    
    <span class="c1"># Determine total duration
</span>    <span class="n">total_duration</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">script</span><span class="p">:</span>
        <span class="n">end_time</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">]</span>
        <span class="k">if</span> <span class="s">"duration"</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
            <span class="n">end_time</span> <span class="o">+=</span> <span class="n">item</span><span class="p">[</span><span class="s">"duration"</span><span class="p">]</span>
        <span class="n">total_duration</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">total_duration</span><span class="p">,</span> <span class="n">end_time</span><span class="p">)</span>
    
    <span class="c1"># Add a small buffer at the end
</span>    <span class="n">total_duration</span> <span class="o">+=</span> <span class="mf">2.0</span>
    
    <span class="c1"># Initialize an empty audio canvas (44.1kHz sample rate)
</span>    <span class="n">sample_rate</span> <span class="o">=</span> <span class="mi">44100</span>
    <span class="n">total_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_duration</span> <span class="o">*</span> <span class="n">sample_rate</span><span class="p">)</span>
    <span class="n">canvas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">total_samples</span><span class="p">)</span>
    
    <span class="c1"># Process each script item
</span>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">script</span><span class="p">):</span>
        <span class="n">start_sample</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">]</span> <span class="o">*</span> <span class="n">sample_rate</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"voice"</span><span class="p">:</span>
            <span class="c1"># Generate voice
</span>            <span class="n">voice_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_voice_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="n">voice_array</span><span class="p">,</span> <span class="n">voice_sr</span> <span class="o">=</span> <span class="n">generate_voice</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> <span class="n">voice_path</span><span class="p">)</span>
            <span class="n">voice_resampled</span> <span class="o">=</span> <span class="n">resample_audio</span><span class="p">(</span><span class="n">voice_array</span><span class="p">,</span> <span class="n">voice_sr</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
            
            <span class="c1"># Add to canvas
</span>            <span class="n">end_sample</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_sample</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">voice_resampled</span><span class="p">),</span> <span class="n">total_samples</span><span class="p">)</span>
            <span class="n">canvas</span><span class="p">[</span><span class="n">start_sample</span><span class="p">:</span><span class="n">end_sample</span><span class="p">]</span> <span class="o">+=</span> <span class="n">voice_resampled</span><span class="p">[:</span><span class="n">end_sample</span><span class="o">-</span><span class="n">start_sample</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span>  <span class="c1"># Full volume
</span>            
        <span class="k">elif</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"sfx"</span><span class="p">:</span>
            <span class="c1"># Generate sound effect
</span>            <span class="n">sfx_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_sfx_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="n">sfx_array</span><span class="p">,</span> <span class="n">sfx_sr</span> <span class="o">=</span> <span class="n">generate_sound_effect</span><span class="p">(</span>
                <span class="n">item</span><span class="p">[</span><span class="s">"description"</span><span class="p">],</span> 
                <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"duration"</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span>
                <span class="n">sfx_path</span>
            <span class="p">)</span>
            <span class="n">sfx_resampled</span> <span class="o">=</span> <span class="n">resample_audio</span><span class="p">(</span><span class="n">sfx_array</span><span class="p">,</span> <span class="n">sfx_sr</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
            
            <span class="c1"># Add to canvas
</span>            <span class="n">end_sample</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_sample</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">sfx_resampled</span><span class="p">),</span> <span class="n">total_samples</span><span class="p">)</span>
            <span class="n">canvas</span><span class="p">[</span><span class="n">start_sample</span><span class="p">:</span><span class="n">end_sample</span><span class="p">]</span> <span class="o">+=</span> <span class="n">sfx_resampled</span><span class="p">[:</span><span class="n">end_sample</span><span class="o">-</span><span class="n">start_sample</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.5</span>  <span class="c1"># Half volume
</span>            
        <span class="k">elif</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"music"</span><span class="p">:</span>
            <span class="c1"># Generate music
</span>            <span class="n">music_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_music_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="n">music_array</span><span class="p">,</span> <span class="n">music_sr</span> <span class="o">=</span> <span class="n">generate_background_music</span><span class="p">(</span>
                <span class="n">item</span><span class="p">[</span><span class="s">"description"</span><span class="p">],</span>
                <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"duration"</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">),</span>
                <span class="n">music_path</span>
            <span class="p">)</span>
            <span class="n">music_resampled</span> <span class="o">=</span> <span class="n">resample_audio</span><span class="p">(</span><span class="n">music_array</span><span class="p">,</span> <span class="n">music_sr</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
            
            <span class="c1"># Add to canvas
</span>            <span class="n">end_sample</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_sample</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">music_resampled</span><span class="p">),</span> <span class="n">total_samples</span><span class="p">)</span>
            <span class="n">canvas</span><span class="p">[</span><span class="n">start_sample</span><span class="p">:</span><span class="n">end_sample</span><span class="p">]</span> <span class="o">+=</span> <span class="n">music_resampled</span><span class="p">[:</span><span class="n">end_sample</span><span class="o">-</span><span class="n">start_sample</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.3</span>  <span class="c1"># Lower volume
</span>    
    <span class="c1"># Normalize to prevent clipping
</span>    <span class="n">max_amplitude</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">canvas</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">max_amplitude</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="n">canvas</span> <span class="o">=</span> <span class="n">canvas</span> <span class="o">/</span> <span class="n">max_amplitude</span>
    
    <span class="c1"># Save the final audio
</span>    <span class="n">wavfile</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">canvas</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Timed audio experience saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="c1"># Clean up temporary files
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">script</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"temp_voice_"</span><span class="p">,</span> <span class="s">"temp_sfx_"</span><span class="p">,</span> <span class="s">"temp_music_"</span><span class="p">]:</span>
            <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">temp_path</span><span class="p">):</span>
                <span class="n">os</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">temp_path</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output_path</span>

<span class="k">def</span> <span class="nf">resample_audio</span><span class="p">(</span><span class="n">audio_array</span><span class="p">,</span> <span class="n">orig_sr</span><span class="p">,</span> <span class="n">target_sr</span><span class="p">):</span>
    <span class="s">"""Resample audio to the target sample rate"""</span>
    <span class="c1"># Convert to torch tensor for resampling
</span>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">audio_array</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">audio_array</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">audio_tensor</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">audio_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">audio_array</span>
        
    <span class="c1"># Resample
</span>    <span class="n">resampled</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">resample</span><span class="p">(</span><span class="n">audio_tensor</span><span class="p">,</span> <span class="n">orig_sr</span><span class="p">,</span> <span class="n">target_sr</span><span class="p">)</span>
    
    <span class="c1"># Return as numpy array
</span>    <span class="k">if</span> <span class="n">resampled</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">resampled</span> <span class="o">=</span> <span class="n">resampled</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">resampled</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="complete-implementation">Complete Implementation</h2>

<p>Let’s put everything together into a complete, runnable example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#!/usr/bin/env python3
# audio_narrative_pipeline.py - Complete TTS and AudioCraft integration pipeline
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">import</span> <span class="nn">scipy.io.wavfile</span> <span class="k">as</span> <span class="n">wavfile</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">audiocraft.models</span> <span class="kn">import</span> <span class="n">MusicGen</span><span class="p">,</span> <span class="n">AudioGen</span>
<span class="kn">from</span> <span class="nn">audiocraft.data.audio</span> <span class="kn">import</span> <span class="n">audio_write</span>
<span class="kn">from</span> <span class="nn">bark</span> <span class="kn">import</span> <span class="n">SAMPLE_RATE</span><span class="p">,</span> <span class="n">generate_audio</span><span class="p">,</span> <span class="n">preload_models</span>

<span class="k">class</span> <span class="nc">AudioNarrativePipeline</span><span class="p">:</span>
    <span class="s">"""
    A comprehensive pipeline for creating audio narratives with voice, music, and sound effects.
    
    This class integrates text-to-speech technology with AudioCraft's music and sound
    generation capabilities to create complete audio experiences from structured scripts.
    
    Key features:
    - Voice generation with emotion control
    - Music and sound effect generation
    - Timeline-based composition
    - Automatic audio mixing and normalization
    - Memory-efficient processing
    
    Example usage:
        pipeline = AudioNarrativePipeline()
        script = [
            {"type": "voice", "text": "Welcome to our journey", "start_time": 0.0},
            {"type": "music", "description": "Ambient music", "start_time": 0.5, "duration": 20.0}
        ]
        pipeline.create_narrative(script, "my_narrative.wav")
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">voice_system</span><span class="o">=</span><span class="s">"bark"</span><span class="p">):</span>
        <span class="s">"""
        Initialize the audio narrative pipeline.
        
        Args:
            use_gpu (bool): Whether to use GPU acceleration if available
            voice_system (str): TTS system to use ('bark', 'elevenlabs', etc.)
        """</span>
        <span class="c1"># Determine device for AudioCraft models
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_setup_device</span><span class="p">()</span> <span class="k">if</span> <span class="n">use_gpu</span> <span class="k">else</span> <span class="s">"cpu"</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">voice_system</span> <span class="o">=</span> <span class="n">voice_system</span>
        
        <span class="c1"># Store models for reuse
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="c1"># Track if TTS models are preloaded
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">tts_initialized</span> <span class="o">=</span> <span class="bp">False</span>
        
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"AudioNarrativePipeline initialized using </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">voice_system</span><span class="si">}</span><span class="s"> for voice and device: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">device</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_setup_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Determine the best available compute device"""</span>
        <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">mps</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">return</span> <span class="s">"mps"</span>  <span class="c1"># Apple Silicon GPU
</span>        <span class="k">elif</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">return</span> <span class="s">"cuda"</span>  <span class="c1"># NVIDIA GPU
</span>        <span class="k">return</span> <span class="s">"cpu"</span>  <span class="c1"># Fallback to CPU
</span>    
    <span class="k">def</span> <span class="nf">_ensure_tts_initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Ensure TTS models are loaded"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">tts_initialized</span> <span class="ow">and</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_system</span> <span class="o">==</span> <span class="s">"bark"</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Initializing Bark TTS models (this may take a moment)..."</span><span class="p">)</span>
            <span class="n">preload_models</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">tts_initialized</span> <span class="o">=</span> <span class="bp">True</span>
    
    <span class="k">def</span> <span class="nf">_get_audiocraft_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_type</span><span class="p">,</span> <span class="n">model_size</span><span class="p">):</span>
        <span class="s">"""
        Get or load an AudioCraft model.
        
        Args:
            model_type (str): 'music' or 'audio'
            model_size (str): Model size ('small', 'medium', 'large')
            
        Returns:
            The loaded model
        """</span>
        <span class="n">model_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">model_size</span><span class="si">}</span><span class="s">"</span>
        
        <span class="k">if</span> <span class="n">model_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Loading </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s"> model (</span><span class="si">{</span><span class="n">model_size</span><span class="si">}</span><span class="s">)..."</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s">"music"</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">MusicGen</span><span class="p">.</span><span class="n">get_pretrained</span><span class="p">(</span><span class="n">model_size</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">model_type</span> <span class="o">==</span> <span class="s">"audio"</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">AudioGen</span><span class="p">.</span><span class="n">get_pretrained</span><span class="p">(</span><span class="n">model_size</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s">"Unknown model type: </span><span class="si">{</span><span class="n">model_type</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
                
            <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span>
            
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="n">model_key</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">generate_voice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">emotion</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"voice_output.wav"</span><span class="p">):</span>
        <span class="s">"""
        Generate voice narration from text.
        
        Args:
            text (str): Text to synthesize
            emotion (str, optional): Emotion to express (used with supported TTS systems)
            output_path (str): Path to save the generated audio
            
        Returns:
            tuple: (audio_array, sample_rate)
        """</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_ensure_tts_initialized</span><span class="p">()</span>
        
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Generating voice: '</span><span class="si">{</span><span class="n">text</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span><span class="si">}</span><span class="s">...'"</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">voice_system</span> <span class="o">==</span> <span class="s">"bark"</span><span class="p">:</span>
            <span class="c1"># Format prompt with emotion if provided
</span>            <span class="k">if</span> <span class="n">emotion</span><span class="p">:</span>
                <span class="n">formatted_text</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"[emotion: </span><span class="si">{</span><span class="n">emotion</span><span class="si">}</span><span class="s">] </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s">"</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">formatted_text</span> <span class="o">=</span> <span class="n">text</span>
                
            <span class="c1"># Generate speech
</span>            <span class="n">speech_array</span> <span class="o">=</span> <span class="n">generate_audio</span><span class="p">(</span><span class="n">formatted_text</span><span class="p">)</span>
            
            <span class="c1"># Save output
</span>            <span class="n">wavfile</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span><span class="p">,</span> <span class="n">speech_array</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">speech_array</span><span class="p">,</span> <span class="n">SAMPLE_RATE</span>
            
        <span class="c1"># Additional voice systems could be added here
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s">"Unsupported voice system: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">voice_system</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">generate_music</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"music_output.wav"</span><span class="p">):</span>
        <span class="s">"""
        Generate background music using MusicGen.
        
        Args:
            prompt (str): Text description of the music
            duration (float): Length in seconds
            temperature (float): Creativity control parameter
            output_path (str): Path to save the generated audio
            
        Returns:
            tuple: (audio_array, sample_rate)
        """</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Generating music: '</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        
        <span class="c1"># Get the MusicGen model
</span>        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_audiocraft_model</span><span class="p">(</span><span class="s">"music"</span><span class="p">,</span> <span class="s">"small"</span><span class="p">)</span>
        
        <span class="c1"># Configure generation parameters
</span>        <span class="n">model</span><span class="p">.</span><span class="n">set_generation_params</span><span class="p">(</span>
            <span class="n">duration</span><span class="o">=</span><span class="n">duration</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="p">)</span>
        
        <span class="c1"># Generate music
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">wav</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">([</span><span class="n">prompt</span><span class="p">])</span>
        
        <span class="c1"># Get sample rate
</span>        <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span>
        
        <span class="c1"># Save the output
</span>        <span class="n">audio_write</span><span class="p">(</span>
            <span class="n">output_path</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'.wav'</span><span class="p">,</span> <span class="s">''</span><span class="p">),</span>
            <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">(),</span>
            <span class="n">sample_rate</span><span class="p">,</span>
            <span class="n">strategy</span><span class="o">=</span><span class="s">"loudness"</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">sample_rate</span>
    
    <span class="k">def</span> <span class="nf">generate_sound_effect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"sfx_output.wav"</span><span class="p">):</span>
        <span class="s">"""
        Generate sound effects using AudioGen.
        
        Args:
            prompt (str): Text description of the sound
            duration (float): Length in seconds
            temperature (float): Creativity control parameter
            output_path (str): Path to save the generated audio
            
        Returns:
            tuple: (audio_array, sample_rate)
        """</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Generating sound effect: '</span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
        
        <span class="c1"># Get the AudioGen model
</span>        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_audiocraft_model</span><span class="p">(</span><span class="s">"audio"</span><span class="p">,</span> <span class="s">"medium"</span><span class="p">)</span>
        
        <span class="c1"># Configure generation parameters
</span>        <span class="n">model</span><span class="p">.</span><span class="n">set_generation_params</span><span class="p">(</span>
            <span class="n">duration</span><span class="o">=</span><span class="n">duration</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="p">)</span>
        
        <span class="c1"># Generate sound effect
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">wav</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">([</span><span class="n">prompt</span><span class="p">])</span>
        
        <span class="c1"># Get sample rate
</span>        <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span>
        
        <span class="c1"># Save the output
</span>        <span class="n">audio_write</span><span class="p">(</span>
            <span class="n">output_path</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'.wav'</span><span class="p">,</span> <span class="s">''</span><span class="p">),</span>
            <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">(),</span>
            <span class="n">sample_rate</span><span class="p">,</span>
            <span class="n">strategy</span><span class="o">=</span><span class="s">"loudness"</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">sample_rate</span>
    
    <span class="k">def</span> <span class="nf">mix_audio_files</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_files</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"mixed_output.wav"</span><span class="p">):</span>
        <span class="s">"""
        Mix multiple audio files with specified weights.
        
        Args:
            audio_files (list): List of audio file paths
            weights (list, optional): Corresponding weights for each file
            output_path (str): Path to save the mixed audio
            
        Returns:
            str: Path to the mixed audio file
        """</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">audio_files</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"No audio files provided for mixing"</span><span class="p">)</span>
        
        <span class="c1"># Default to equal weights if not specified
</span>        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">)]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">)</span>
        
        <span class="c1"># Validate weights
</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">audio_files</span><span class="p">):</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Number of weights must match number of audio files"</span><span class="p">)</span>
        
        <span class="c1"># Load all audio files
</span>        <span class="n">loaded_audio</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sample_rates</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">audio_files</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
                <span class="k">raise</span> <span class="nb">FileNotFoundError</span><span class="p">(</span><span class="sa">f</span><span class="s">"Audio file not found: </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
                
            <span class="c1"># Load the audio
</span>            <span class="n">waveform</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">loaded_audio</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>
            <span class="n">sample_rates</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sr</span><span class="p">)</span>
        
        <span class="c1"># Use the first sample rate as reference
</span>        <span class="n">reference_sr</span> <span class="o">=</span> <span class="n">sample_rates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Convert all audio to the same format (mono, same sample rate)
</span>        <span class="n">processed_audio</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">loaded_audio</span><span class="p">,</span> <span class="n">sample_rates</span><span class="p">)):</span>
            <span class="c1"># Convert to mono if stereo
</span>            <span class="k">if</span> <span class="n">audio</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                
            <span class="c1"># Resample if needed
</span>            <span class="k">if</span> <span class="n">sr</span> <span class="o">!=</span> <span class="n">reference_sr</span><span class="p">:</span>
                <span class="n">audio</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">resample</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="n">reference_sr</span><span class="p">)</span>
                
            <span class="n">processed_audio</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="c1"># Find the longest audio length
</span>        <span class="n">max_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">audio</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">audio</span> <span class="ow">in</span> <span class="n">processed_audio</span><span class="p">)</span>
        
        <span class="c1"># Mix audio with weights
</span>        <span class="n">mixed_audio</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_length</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">processed_audio</span><span class="p">,</span> <span class="n">weights</span><span class="p">)):</span>
            <span class="c1"># Pad shorter audio with silence
</span>            <span class="k">if</span> <span class="n">audio</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_length</span><span class="p">:</span>
                <span class="n">padding</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_length</span> <span class="o">-</span> <span class="n">audio</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">audio</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">audio</span><span class="p">,</span> <span class="n">padding</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Add weighted audio to the mix
</span>            <span class="n">mixed_audio</span> <span class="o">+=</span> <span class="n">audio</span> <span class="o">*</span> <span class="n">weight</span>
        
        <span class="c1"># Normalize to prevent clipping
</span>        <span class="n">max_amplitude</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">mixed_audio</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">max_amplitude</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">mixed_audio</span> <span class="o">=</span> <span class="n">mixed_audio</span> <span class="o">/</span> <span class="n">max_amplitude</span>
        
        <span class="c1"># Save the mixed audio
</span>        <span class="n">torchaudio</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">mixed_audio</span><span class="p">,</span> <span class="n">reference_sr</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Mixed audio saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output_path</span>
    
    <span class="k">def</span> <span class="nf">create_narrative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">script</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"narrative_output.wav"</span><span class="p">,</span> <span class="n">cleanup_temp</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="s">"""
        Create a complete audio narrative from a script.
        
        Args:
            script (list): List of script elements with timing and content
            output_path (str): Path to save the final narrative
            cleanup_temp (bool): Whether to remove temporary files after processing
            
        Returns:
            str: Path to the final narrative audio file
        """</span>
        <span class="c1"># Sort script by start time
</span>        <span class="n">script</span><span class="p">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"start_time"</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        
        <span class="c1"># Determine total duration
</span>        <span class="n">total_duration</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">script</span><span class="p">:</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"start_time"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="s">"duration"</span> <span class="ow">in</span> <span class="n">item</span><span class="p">:</span>
                <span class="n">end_time</span> <span class="o">+=</span> <span class="n">item</span><span class="p">[</span><span class="s">"duration"</span><span class="p">]</span>
            <span class="n">total_duration</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">total_duration</span><span class="p">,</span> <span class="n">end_time</span><span class="p">)</span>
        
        <span class="c1"># Add a small buffer at the end
</span>        <span class="n">total_duration</span> <span class="o">+=</span> <span class="mf">2.0</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Creating narrative with total duration: </span><span class="si">{</span><span class="n">total_duration</span><span class="p">:.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>
        
        <span class="c1"># Initialize an empty audio canvas (44.1kHz sample rate)
</span>        <span class="n">sample_rate</span> <span class="o">=</span> <span class="mi">44100</span>
        <span class="n">total_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_duration</span> <span class="o">*</span> <span class="n">sample_rate</span><span class="p">)</span>
        <span class="n">canvas</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">total_samples</span><span class="p">)</span>
        
        <span class="c1"># Keep track of temporary files
</span>        <span class="n">temp_files</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Process each script item
</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">script</span><span class="p">):</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"start_time"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">start_sample</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">start_time</span> <span class="o">*</span> <span class="n">sample_rate</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"voice"</span><span class="p">:</span>
                <span class="c1"># Generate voice
</span>                <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_voice_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
                <span class="n">voice_array</span><span class="p">,</span> <span class="n">voice_sr</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generate_voice</span><span class="p">(</span>
                    <span class="n">item</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span>
                    <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"emotion"</span><span class="p">),</span>
                    <span class="n">temp_path</span>
                <span class="p">)</span>
                <span class="n">temp_files</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp_path</span><span class="p">)</span>
                
                <span class="c1"># Resample if needed
</span>                <span class="n">voice_resampled</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_resample_audio</span><span class="p">(</span><span class="n">voice_array</span><span class="p">,</span> <span class="n">voice_sr</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
                
                <span class="c1"># Add to canvas
</span>                <span class="n">end_sample</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_sample</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">voice_resampled</span><span class="p">),</span> <span class="n">total_samples</span><span class="p">)</span>
                <span class="n">canvas</span><span class="p">[</span><span class="n">start_sample</span><span class="p">:</span><span class="n">end_sample</span><span class="p">]</span> <span class="o">+=</span> <span class="n">voice_resampled</span><span class="p">[:</span><span class="n">end_sample</span><span class="o">-</span><span class="n">start_sample</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.0</span>  <span class="c1"># Full volume
</span>                
            <span class="k">elif</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"music"</span><span class="p">:</span>
                <span class="c1"># Generate music
</span>                <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_music_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
                <span class="n">music_array</span><span class="p">,</span> <span class="n">music_sr</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generate_music</span><span class="p">(</span>
                    <span class="n">item</span><span class="p">[</span><span class="s">"description"</span><span class="p">],</span>
                    <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"duration"</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">),</span>
                    <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"temperature"</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">),</span>
                    <span class="n">temp_path</span>
                <span class="p">)</span>
                <span class="n">temp_files</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp_path</span><span class="p">)</span>
                
                <span class="c1"># Resample if needed
</span>                <span class="n">music_resampled</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_resample_audio</span><span class="p">(</span><span class="n">music_array</span><span class="p">,</span> <span class="n">music_sr</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
                
                <span class="c1"># Add to canvas
</span>                <span class="n">end_sample</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_sample</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">music_resampled</span><span class="p">),</span> <span class="n">total_samples</span><span class="p">)</span>
                <span class="n">canvas</span><span class="p">[</span><span class="n">start_sample</span><span class="p">:</span><span class="n">end_sample</span><span class="p">]</span> <span class="o">+=</span> <span class="n">music_resampled</span><span class="p">[:</span><span class="n">end_sample</span><span class="o">-</span><span class="n">start_sample</span><span class="p">]</span> <span class="o">*</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"volume"</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
                
            <span class="k">elif</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"sfx"</span><span class="p">:</span>
                <span class="c1"># Generate sound effect
</span>                <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_sfx_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
                <span class="n">sfx_array</span><span class="p">,</span> <span class="n">sfx_sr</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generate_sound_effect</span><span class="p">(</span>
                    <span class="n">item</span><span class="p">[</span><span class="s">"description"</span><span class="p">],</span>
                    <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"duration"</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span>
                    <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"temperature"</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                    <span class="n">temp_path</span>
                <span class="p">)</span>
                <span class="n">temp_files</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp_path</span><span class="p">)</span>
                
                <span class="c1"># Resample if needed
</span>                <span class="n">sfx_resampled</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_resample_audio</span><span class="p">(</span><span class="n">sfx_array</span><span class="p">,</span> <span class="n">sfx_sr</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
                
                <span class="c1"># Add to canvas
</span>                <span class="n">end_sample</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start_sample</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">sfx_resampled</span><span class="p">),</span> <span class="n">total_samples</span><span class="p">)</span>
                <span class="n">canvas</span><span class="p">[</span><span class="n">start_sample</span><span class="p">:</span><span class="n">end_sample</span><span class="p">]</span> <span class="o">+=</span> <span class="n">sfx_resampled</span><span class="p">[:</span><span class="n">end_sample</span><span class="o">-</span><span class="n">start_sample</span><span class="p">]</span> <span class="o">*</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"volume"</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        
        <span class="c1"># Normalize to prevent clipping
</span>        <span class="n">max_amplitude</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">canvas</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">max_amplitude</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
            <span class="n">canvas</span> <span class="o">=</span> <span class="n">canvas</span> <span class="o">/</span> <span class="n">max_amplitude</span>
        
        <span class="c1"># Save the final audio
</span>        <span class="n">wavfile</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">,</span> <span class="n">canvas</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Audio narrative saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
        <span class="c1"># Clean up temporary files if requested
</span>        <span class="k">if</span> <span class="n">cleanup_temp</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">temp_file</span> <span class="ow">in</span> <span class="n">temp_files</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">temp_file</span><span class="p">):</span>
                    <span class="n">os</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">temp_file</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Cleaned up </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">temp_files</span><span class="p">)</span><span class="si">}</span><span class="s"> temporary files"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output_path</span>
    
    <span class="k">def</span> <span class="nf">_resample_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">audio_array</span><span class="p">,</span> <span class="n">orig_sr</span><span class="p">,</span> <span class="n">target_sr</span><span class="p">):</span>
        <span class="s">"""
        Resample audio to the target sample rate.
        
        Args:
            audio_array: Audio data
            orig_sr: Original sample rate
            target_sr: Target sample rate
            
        Returns:
            Resampled audio as numpy array
        """</span>
        <span class="c1"># Skip if already at target rate
</span>        <span class="k">if</span> <span class="n">orig_sr</span> <span class="o">==</span> <span class="n">target_sr</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">audio_array</span>
            
        <span class="c1"># Convert to torch tensor for resampling
</span>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">audio_array</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">audio_array</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">audio_tensor</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">audio_tensor</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">audio_array</span>
            
        <span class="c1"># Resample
</span>        <span class="n">resampled</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">resample</span><span class="p">(</span><span class="n">audio_tensor</span><span class="p">,</span> <span class="n">orig_sr</span><span class="p">,</span> <span class="n">target_sr</span><span class="p">)</span>
        
        <span class="c1"># Return as numpy array
</span>        <span class="k">if</span> <span class="n">resampled</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">resampled</span> <span class="o">=</span> <span class="n">resampled</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">resampled</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">free_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Release memory used by models"""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">tts_initialized</span> <span class="o">=</span> <span class="bp">False</span>
        
        <span class="c1"># Force garbage collection
</span>        <span class="kn">import</span> <span class="nn">gc</span>
        <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>
        
        <span class="c1"># Clear CUDA cache if using GPU
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">device</span> <span class="o">==</span> <span class="s">"cuda"</span><span class="p">:</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">empty_cache</span><span class="p">()</span>
            
        <span class="k">print</span><span class="p">(</span><span class="s">"Memory released"</span><span class="p">)</span>

<span class="c1"># Example usage
</span><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="c1"># Create the pipeline
</span>    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">AudioNarrativePipeline</span><span class="p">()</span>
    
    <span class="c1"># Define a narrative script
</span>    <span class="n">forest_journey_script</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># Introduction with excited voice
</span>        <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"voice"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"Welcome to our journey through the magical forest!"</span><span class="p">,</span> 
         <span class="s">"emotion"</span><span class="p">:</span> <span class="s">"excited"</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
        
        <span class="c1"># Background music starts slightly after voice
</span>        <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"music"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Peaceful fantasy music with soft flutes and mystical bells"</span><span class="p">,</span> 
         <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">20.0</span><span class="p">,</span> <span class="s">"volume"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">},</span>
        
        <span class="c1"># Forest ambience fades in
</span>        <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"sfx"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Forest ambience with birds chirping and leaves rustling"</span><span class="p">,</span> 
         <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">3.0</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">17.0</span><span class="p">,</span> <span class="s">"volume"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">},</span>
        
        <span class="c1"># Next voice segment
</span>        <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"voice"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"Listen carefully to the sounds of nature all around us."</span><span class="p">,</span> 
         <span class="s">"emotion"</span><span class="p">:</span> <span class="s">"calm"</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">6.0</span><span class="p">},</span>
        
        <span class="c1"># Special sound effect
</span>        <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"sfx"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Magical shimmer sound with wind chimes"</span><span class="p">,</span> 
         <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">10.0</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">3.0</span><span class="p">,</span> <span class="s">"volume"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
        
        <span class="c1"># Final voice segment
</span>        <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"voice"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"Oh! Did you hear that? I think we've discovered something magical!"</span><span class="p">,</span> 
         <span class="s">"emotion"</span><span class="p">:</span> <span class="s">"surprised"</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="mf">12.0</span><span class="p">}</span>
    <span class="p">]</span>
    
    <span class="c1"># Create the narrative
</span>    <span class="n">pipeline</span><span class="p">.</span><span class="n">create_narrative</span><span class="p">(</span>
        <span class="n">script</span><span class="o">=</span><span class="n">forest_journey_script</span><span class="p">,</span>
        <span class="n">output_path</span><span class="o">=</span><span class="s">"magical_forest_journey.wav"</span>
    <span class="p">)</span>
    
    <span class="c1"># Release memory
</span>    <span class="n">pipeline</span><span class="p">.</span><span class="n">free_memory</span><span class="p">()</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"Narrative creation complete!"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="variations-and-customizations">Variations and Customizations</h2>

<p>Let’s explore some variations of our solution to address different needs or preferences.</p>

<h3 id="variation-1-using-elevenlabs-for-higher-quality-voices">Variation 1: Using ElevenLabs for Higher Quality Voices</h3>

<p>ElevenLabs provides exceptionally high-quality voice synthesis. Here’s how to integrate it into our pipeline:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">class</span> <span class="nc">ElevenLabsVoiceGenerator</span><span class="p">:</span>
    <span class="s">"""Voice generation using ElevenLabs API"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""
        Initialize the ElevenLabs voice generator.
        
        Args:
            api_key (str, optional): API key for ElevenLabs. If not provided,
                                    looks for ELEVEN_API_KEY environment variable.
        """</span>
        <span class="c1"># Get API key from environment if not provided
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key</span> <span class="ow">or</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"ELEVEN_API_KEY"</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">api_key</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"ElevenLabs API key required. Set ELEVEN_API_KEY environment variable or pass as parameter."</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">generate_voice</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">voice_id</span><span class="o">=</span><span class="s">"21m00Tcm4TlvDq8ikWAM"</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"elevenlabs_output.wav"</span><span class="p">,</span>
                      <span class="n">stability</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">similarity_boost</span><span class="o">=</span><span class="mf">0.75</span><span class="p">):</span>
        <span class="s">"""
        Generate speech using ElevenLabs API.
        
        Args:
            text (str): Text to convert to speech
            voice_id (str): ElevenLabs voice ID
            output_path (str): Path to save output audio
            stability (float): Voice stability (0.0-1.0)
            similarity_boost (float): Voice similarity boost (0.0-1.0)
            
        Returns:
            tuple: (Path to saved audio, sample rate)
        """</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Generating speech with ElevenLabs: '</span><span class="si">{</span><span class="n">text</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span><span class="si">}</span><span class="s">...'"</span><span class="p">)</span>
        
        <span class="c1"># API endpoint
</span>        <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"https://api.elevenlabs.io/v1/text-to-speech/</span><span class="si">{</span><span class="n">voice_id</span><span class="si">}</span><span class="s">"</span>
        
        <span class="c1"># Request headers
</span>        <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"Accept"</span><span class="p">:</span> <span class="s">"audio/mpeg"</span><span class="p">,</span>
            <span class="s">"Content-Type"</span><span class="p">:</span> <span class="s">"application/json"</span><span class="p">,</span>
            <span class="s">"xi-api-key"</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">api_key</span>
        <span class="p">}</span>
        
        <span class="c1"># Request data
</span>        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"text"</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
            <span class="s">"model_id"</span><span class="p">:</span> <span class="s">"eleven_monolingual_v1"</span><span class="p">,</span>
            <span class="s">"voice_settings"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">"stability"</span><span class="p">:</span> <span class="n">stability</span><span class="p">,</span>
                <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="n">similarity_boost</span>
            <span class="p">}</span>
        <span class="p">}</span>
        
        <span class="c1"># Make API call
</span>        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
        
        <span class="c1"># Check for success
</span>        <span class="k">if</span> <span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
            <span class="c1"># Save audio file
</span>            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
                <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"ElevenLabs audio saved to </span><span class="si">{</span><span class="n">output_path</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
            
            <span class="c1"># Get audio info using torchaudio
</span>            <span class="n">info</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="n">output_path</span><span class="p">)</span>
            <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">info</span><span class="p">.</span><span class="n">sample_rate</span>
            
            <span class="k">return</span> <span class="n">output_path</span><span class="p">,</span> <span class="n">sample_rate</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Handle error
</span>            <span class="n">error_msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"ElevenLabs API Error: </span><span class="si">{</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span><span class="si">}</span><span class="s">"</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">error_details</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">json</span><span class="p">()</span>
                <span class="n">error_msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s">" - </span><span class="si">{</span><span class="n">error_details</span><span class="si">}</span><span class="s">"</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
            <span class="k">raise</span> <span class="nb">Exception</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">generate_voice_with_emotion</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">emotion</span><span class="o">=</span><span class="s">"neutral"</span><span class="p">,</span> <span class="n">voice_id</span><span class="o">=</span><span class="s">"21m00Tcm4TlvDq8ikWAM"</span><span class="p">,</span> 
                                   <span class="n">output_path</span><span class="o">=</span><span class="s">"elevenlabs_emotion_output.wav"</span><span class="p">):</span>
        <span class="s">"""
        Generate speech with emotional expression.
        
        Args:
            text (str): Text to convert to speech
            emotion (str): Desired emotion (neutral, happy, sad, angry, etc.)
            voice_id (str): ElevenLabs voice ID
            output_path (str): Path to save output audio
            
        Returns:
            tuple: (Path to saved audio, sample rate)
        """</span>
        <span class="c1"># Map emotions to voice settings
</span>        <span class="n">emotion_settings</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"neutral"</span><span class="p">:</span> <span class="p">{</span><span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.75</span><span class="p">},</span>
            <span class="s">"happy"</span><span class="p">:</span> <span class="p">{</span><span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.65</span><span class="p">},</span>
            <span class="s">"excited"</span><span class="p">:</span> <span class="p">{</span><span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">},</span>
            <span class="s">"sad"</span><span class="p">:</span> <span class="p">{</span><span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">},</span>
            <span class="s">"angry"</span><span class="p">:</span> <span class="p">{</span><span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">},</span>
            <span class="s">"fear"</span><span class="p">:</span> <span class="p">{</span><span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">},</span>
            <span class="s">"surprise"</span><span class="p">:</span> <span class="p">{</span><span class="s">"stability"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">"similarity_boost"</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">}</span>
        <span class="p">}</span>
        
        <span class="c1"># Get settings for the emotion (default to neutral if not found)
</span>        <span class="n">settings</span> <span class="o">=</span> <span class="n">emotion_settings</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">emotion</span><span class="p">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">emotion_settings</span><span class="p">[</span><span class="s">"neutral"</span><span class="p">])</span>
        
        <span class="c1"># Add emotion context to the text for better expression
</span>        <span class="n">emotion_prefixes</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"happy"</span><span class="p">:</span> <span class="s">"😊 [Happily] "</span><span class="p">,</span>
            <span class="s">"excited"</span><span class="p">:</span> <span class="s">"🤩 [Excitedly] "</span><span class="p">,</span>
            <span class="s">"sad"</span><span class="p">:</span> <span class="s">"😢 [Sadly] "</span><span class="p">,</span>
            <span class="s">"angry"</span><span class="p">:</span> <span class="s">"😠 [Angrily] "</span><span class="p">,</span>
            <span class="s">"fear"</span><span class="p">:</span> <span class="s">"😨 [Fearfully] "</span><span class="p">,</span>
            <span class="s">"surprise"</span><span class="p">:</span> <span class="s">"😲 [Surprised] "</span><span class="p">,</span>
            <span class="s">"neutral"</span><span class="p">:</span> <span class="s">""</span>
        <span class="p">}</span>
        
        <span class="c1"># Add emotion prefix if available
</span>        <span class="n">prefix</span> <span class="o">=</span> <span class="n">emotion_prefixes</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">emotion</span><span class="p">.</span><span class="n">lower</span><span class="p">(),</span> <span class="s">""</span><span class="p">)</span>
        <span class="n">enhanced_text</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="n">text</span>
        
        <span class="c1"># Generate speech with emotion-specific settings
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">generate_voice</span><span class="p">(</span>
            <span class="n">text</span><span class="o">=</span><span class="n">enhanced_text</span><span class="p">,</span>
            <span class="n">voice_id</span><span class="o">=</span><span class="n">voice_id</span><span class="p">,</span>
            <span class="n">output_path</span><span class="o">=</span><span class="n">output_path</span><span class="p">,</span>
            <span class="n">stability</span><span class="o">=</span><span class="n">settings</span><span class="p">[</span><span class="s">"stability"</span><span class="p">],</span>
            <span class="n">similarity_boost</span><span class="o">=</span><span class="n">settings</span><span class="p">[</span><span class="s">"similarity_boost"</span><span class="p">]</span>
        <span class="p">)</span>

<span class="c1"># To use in the main pipeline:
# 1. Replace the generate_voice method in AudioNarrativePipeline
# 2. Initialize the ElevenLabsVoiceGenerator in the constructor
</span></code></pre></div></div>

<h3 id="variation-2-advanced-script-format-with-scene-based-organization">Variation 2: Advanced Script Format with Scene-Based Organization</h3>

<p>For more complex narratives, a scene-based script format can be more manageable:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_narrative_from_scenes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scenes</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"narrative_with_scenes.wav"</span><span class="p">):</span>
    <span class="s">"""
    Create an audio narrative from a scene-based script format.
    
    Args:
        scenes (list): List of scene dictionaries, each containing:
            - name: Scene name
            - description: Scene description
            - elements: List of audio elements in the scene
            - transitions: Optional transition specifications
        output_path (str): Path to save the final narrative
        
    Returns:
        str: Path to the final narrative audio file
    """</span>
    <span class="c1"># Convert scene-based format to flat timeline
</span>    <span class="n">timeline</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_time</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">scene</span> <span class="ow">in</span> <span class="n">scenes</span><span class="p">:</span>
        <span class="n">scene_name</span> <span class="o">=</span> <span class="n">scene</span><span class="p">[</span><span class="s">"name"</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Processing scene: </span><span class="si">{</span><span class="n">scene_name</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
        <span class="c1"># Add scene elements to timeline
</span>        <span class="n">scene_elements</span> <span class="o">=</span> <span class="n">scene</span><span class="p">[</span><span class="s">"elements"</span><span class="p">]</span>
        <span class="n">scene_duration</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">scene_elements</span><span class="p">:</span>
            <span class="c1"># Calculate element start time (relative to scene start + specified offset)
</span>            <span class="n">element_start</span> <span class="o">=</span> <span class="n">current_time</span> <span class="o">+</span> <span class="n">element</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"offset"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            
            <span class="c1"># Add element to timeline with absolute start time
</span>            <span class="n">timeline_element</span> <span class="o">=</span> <span class="n">element</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">timeline_element</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">]</span> <span class="o">=</span> <span class="n">element_start</span>
            <span class="n">timeline</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">timeline_element</span><span class="p">)</span>
            
            <span class="c1"># Track scene duration based on elements
</span>            <span class="n">element_end</span> <span class="o">=</span> <span class="n">element_start</span>
            <span class="k">if</span> <span class="s">"duration"</span> <span class="ow">in</span> <span class="n">element</span><span class="p">:</span>
                <span class="n">element_end</span> <span class="o">+=</span> <span class="n">element</span><span class="p">[</span><span class="s">"duration"</span><span class="p">]</span>
            <span class="n">scene_duration</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">scene_duration</span><span class="p">,</span> <span class="n">element_end</span> <span class="o">-</span> <span class="n">current_time</span><span class="p">)</span>
        
        <span class="c1"># Add transition if specified
</span>        <span class="k">if</span> <span class="s">"transition"</span> <span class="ow">in</span> <span class="n">scene</span><span class="p">:</span>
            <span class="n">transition</span> <span class="o">=</span> <span class="n">scene</span><span class="p">[</span><span class="s">"transition"</span><span class="p">]</span>
            <span class="n">timeline</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"type"</span><span class="p">:</span> <span class="s">"sfx"</span><span class="p">,</span>
                <span class="s">"description"</span><span class="p">:</span> <span class="n">transition</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"description"</span><span class="p">,</span> <span class="s">"Smooth transition effect"</span><span class="p">),</span>
                <span class="s">"start_time"</span><span class="p">:</span> <span class="n">current_time</span> <span class="o">+</span> <span class="n">scene_duration</span> <span class="o">-</span> <span class="n">transition</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"overlap"</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                <span class="s">"duration"</span><span class="p">:</span> <span class="n">transition</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"duration"</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
                <span class="s">"volume"</span><span class="p">:</span> <span class="n">transition</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"volume"</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">)</span>
            <span class="p">})</span>
        
        <span class="c1"># Update current time for next scene
</span>        <span class="n">current_time</span> <span class="o">+=</span> <span class="n">scene_duration</span>
    
    <span class="c1"># Create narrative from the flattened timeline
</span>    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">create_narrative</span><span class="p">(</span><span class="n">timeline</span><span class="p">,</span> <span class="n">output_path</span><span class="p">)</span>

<span class="c1"># Example usage:
</span><span class="n">scenes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s">"name"</span><span class="p">:</span> <span class="s">"Forest Introduction"</span><span class="p">,</span>
        <span class="s">"description"</span><span class="p">:</span> <span class="s">"Introducing the magical forest setting"</span><span class="p">,</span>
        <span class="s">"elements"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"voice"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"Welcome to the magical forest!"</span><span class="p">,</span> <span class="s">"emotion"</span><span class="p">:</span> <span class="s">"excited"</span><span class="p">,</span> <span class="s">"offset"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
            <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"music"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Magical forest theme with flutes"</span><span class="p">,</span> <span class="s">"offset"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">15.0</span><span class="p">,</span> <span class="s">"volume"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">},</span>
            <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"sfx"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Forest ambience with birds"</span><span class="p">,</span> <span class="s">"offset"</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">12.0</span><span class="p">,</span> <span class="s">"volume"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">}</span>
        <span class="p">],</span>
        <span class="s">"transition"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"description"</span><span class="p">:</span> <span class="s">"Magical shimmer transition"</span><span class="p">,</span>
            <span class="s">"duration"</span><span class="p">:</span> <span class="mf">3.0</span><span class="p">,</span>
            <span class="s">"overlap"</span><span class="p">:</span> <span class="mf">2.0</span>
        <span class="p">}</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s">"name"</span><span class="p">:</span> <span class="s">"Mysterious Discovery"</span><span class="p">,</span>
        <span class="s">"description"</span><span class="p">:</span> <span class="s">"Characters discover something in the forest"</span><span class="p">,</span>
        <span class="s">"elements"</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"voice"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"What's that glowing behind the trees?"</span><span class="p">,</span> <span class="s">"emotion"</span><span class="p">:</span> <span class="s">"surprised"</span><span class="p">,</span> <span class="s">"offset"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"sfx"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Mysterious magical glow sound"</span><span class="p">,</span> <span class="s">"offset"</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">5.0</span><span class="p">,</span> <span class="s">"volume"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">"type"</span><span class="p">:</span> <span class="s">"music"</span><span class="p">,</span> <span class="s">"description"</span><span class="p">:</span> <span class="s">"Suspenseful mysterious music with strings"</span><span class="p">,</span> <span class="s">"offset"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s">"duration"</span><span class="p">:</span> <span class="mf">20.0</span><span class="p">,</span> <span class="s">"volume"</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">}</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="c1"># pipeline.create_narrative_from_scenes(scenes, "forest_adventure.wav")
</span></code></pre></div></div>

<h2 id="common-pitfalls-and-troubleshooting">Common Pitfalls and Troubleshooting</h2>

<h3 id="problem-tts-voice-quality-issues">Problem: TTS Voice Quality Issues</h3>

<p>TTS systems can sometimes produce speech with unnatural pronunciation, especially for unusual words or names.</p>

<p><strong>Solution</strong>:</p>
<ul>
  <li>Use phonetic spelling or SSML markup for difficult words</li>
  <li>Try different voice models for the specific content type</li>
  <li>Break long sentences into shorter phrases with appropriate pauses:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">enhance_speech_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="s">"""Enhance text for better TTS quality"""</span>
    <span class="c1"># Replace difficult words with phonetic versions or SSML
</span>    <span class="n">replacements</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"AudioCraft"</span><span class="p">:</span> <span class="s">"Audio Craft"</span><span class="p">,</span>
        <span class="s">"MusicGen"</span><span class="p">:</span> <span class="s">"Music Gen"</span><span class="p">,</span>
        <span class="s">"ElevenLabs"</span><span class="p">:</span> <span class="s">"Eleven Labs"</span>
    <span class="p">}</span>
    
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">replacement</span> <span class="ow">in</span> <span class="n">replacements</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">replacement</span><span class="p">)</span>
    
    <span class="c1"># Add pauses at punctuation for more natural speech
</span>    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"."</span><span class="p">,</span> <span class="s">".[pause]"</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"!"</span><span class="p">,</span> <span class="s">"![pause]"</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"?"</span><span class="p">,</span> <span class="s">"?[pause]"</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">","</span><span class="p">,</span> <span class="s">",[micropause]"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">text</span>

<span class="c1"># Usage
</span><span class="n">enhanced_text</span> <span class="o">=</span> <span class="n">enhance_speech_text</span><span class="p">(</span><span class="s">"Welcome to AudioCraft, the remarkable AI tool for music generation!"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="problem-audio-synchronization-issues">Problem: Audio Synchronization Issues</h3>

<p>When creating complex narratives, timing can be challenging because TTS generation produces variable-length outputs.</p>

<p><strong>Solution</strong>:</p>
<ul>
  <li>First generate all TTS segments to determine their actual durations</li>
  <li>Adjust the timeline based on actual durations rather than estimates</li>
  <li>Use padding or trimming to ensure precise alignment:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_precisely_timed_narrative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">script</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"precise_narrative.wav"</span><span class="p">):</span>
    <span class="s">"""Create narrative with precise timing based on pre-generated TTS"""</span>
    <span class="c1"># First, generate all voice segments to get actual durations
</span>    <span class="n">voice_segments</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">script</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"voice"</span><span class="p">:</span>
            <span class="c1"># Generate voice
</span>            <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_voice_</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">voice_segments</span><span class="p">)</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">generate_voice</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"emotion"</span><span class="p">),</span> <span class="n">temp_path</span><span class="p">)</span>
            
            <span class="c1"># Get duration
</span>            <span class="n">info</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="n">temp_path</span><span class="p">)</span>
            <span class="n">duration</span> <span class="o">=</span> <span class="n">info</span><span class="p">.</span><span class="n">num_frames</span> <span class="o">/</span> <span class="n">info</span><span class="p">.</span><span class="n">sample_rate</span>
            
            <span class="c1"># Store segment info
</span>            <span class="n">voice_segments</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"path"</span><span class="p">:</span> <span class="n">temp_path</span><span class="p">,</span>
                <span class="s">"duration"</span><span class="p">:</span> <span class="n">duration</span><span class="p">,</span>
                <span class="s">"start_time"</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">],</span>
                <span class="s">"original_idx"</span><span class="p">:</span> <span class="n">script</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
            <span class="p">})</span>
    
    <span class="c1"># Now adjust timeline based on actual durations
</span>    <span class="n">adjusted_script</span> <span class="o">=</span> <span class="n">script</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">segment</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">voice_segments</span><span class="p">):</span>
        <span class="n">original_idx</span> <span class="o">=</span> <span class="n">segment</span><span class="p">[</span><span class="s">"original_idx"</span><span class="p">]</span>
        <span class="n">actual_duration</span> <span class="o">=</span> <span class="n">segment</span><span class="p">[</span><span class="s">"duration"</span><span class="p">]</span>
        
        <span class="c1"># Update script with actual path and duration
</span>        <span class="n">adjusted_script</span><span class="p">[</span><span class="n">original_idx</span><span class="p">][</span><span class="s">"audio_path"</span><span class="p">]</span> <span class="o">=</span> <span class="n">segment</span><span class="p">[</span><span class="s">"path"</span><span class="p">]</span>
        <span class="n">adjusted_script</span><span class="p">[</span><span class="n">original_idx</span><span class="p">][</span><span class="s">"actual_duration"</span><span class="p">]</span> <span class="o">=</span> <span class="n">actual_duration</span>
    
    <span class="c1"># Process the adjusted script
</span>    <span class="c1"># [Implementation would use pre-generated audio files and adjust other elements as needed]
</span></code></pre></div></div>

<h3 id="problem-memory-management-with-multiple-models">Problem: Memory Management with Multiple Models</h3>

<p>Loading multiple large models simultaneously can cause out-of-memory errors.</p>

<p><strong>Solution</strong>:</p>
<ul>
  <li>Implement staged generation where only one model is loaded at a time</li>
  <li>Use model unloading to free resources after generation</li>
  <li>Process audio in smaller batches:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">staged_generation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">script</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s">"staged_output.wav"</span><span class="p">):</span>
    <span class="s">"""Generate audio in stages to manage memory usage"""</span>
    <span class="c1"># Temporary output paths
</span>    <span class="n">voice_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">music_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">sfx_outputs</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Stage 1: Generate all voice segments
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">_ensure_tts_initialized</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Stage 1: Generating voice segments..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">script</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"voice"</span><span class="p">:</span>
            <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_voice_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">generate_voice</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"emotion"</span><span class="p">),</span> <span class="n">temp_path</span><span class="p">)</span>
            <span class="n">voice_outputs</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"path"</span><span class="p">:</span> <span class="n">temp_path</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">]})</span>
    
    <span class="c1"># Free TTS resources
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">tts_initialized</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="kn">import</span> <span class="nn">gc</span>
    <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>
    
    <span class="c1"># Stage 2: Generate all music
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"Stage 2: Generating music..."</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_audiocraft_model</span><span class="p">(</span><span class="s">"music"</span><span class="p">,</span> <span class="s">"small"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">script</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"music"</span><span class="p">:</span>
            <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_music_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="n">duration</span> <span class="o">=</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"duration"</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
            
            <span class="c1"># Generate with MusicGen
</span>            <span class="n">model</span><span class="p">.</span><span class="n">set_generation_params</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="n">duration</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"temperature"</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">))</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">wav</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s">"description"</span><span class="p">]])</span>
            
            <span class="c1"># Save output
</span>            <span class="n">audio_write</span><span class="p">(</span><span class="n">temp_path</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'.wav'</span><span class="p">,</span> <span class="s">''</span><span class="p">),</span> <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">)</span>
            <span class="n">music_outputs</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"path"</span><span class="p">:</span> <span class="n">temp_path</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">]})</span>
    
    <span class="c1"># Free music model
</span>    <span class="k">del</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="s">"music_small"</span><span class="p">]</span>
    <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>
    
    <span class="c1"># Stage 3: Generate all sound effects
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"Stage 3: Generating sound effects..."</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_audiocraft_model</span><span class="p">(</span><span class="s">"audio"</span><span class="p">,</span> <span class="s">"medium"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">script</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">item</span><span class="p">[</span><span class="s">"type"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"sfx"</span><span class="p">:</span>
            <span class="n">temp_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"temp_sfx_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.wav"</span>
            <span class="n">duration</span> <span class="o">=</span> <span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"duration"</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
            
            <span class="c1"># Generate with AudioGen
</span>            <span class="n">model</span><span class="p">.</span><span class="n">set_generation_params</span><span class="p">(</span><span class="n">duration</span><span class="o">=</span><span class="n">duration</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="n">item</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"temperature"</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">wav</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s">"description"</span><span class="p">]])</span>
            
            <span class="c1"># Save output
</span>            <span class="n">audio_write</span><span class="p">(</span><span class="n">temp_path</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'.wav'</span><span class="p">,</span> <span class="s">''</span><span class="p">),</span> <span class="n">wav</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">model</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">)</span>
            <span class="n">sfx_outputs</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">"path"</span><span class="p">:</span> <span class="n">temp_path</span><span class="p">,</span> <span class="s">"start_time"</span><span class="p">:</span> <span class="n">item</span><span class="p">[</span><span class="s">"start_time"</span><span class="p">]})</span>
    
    <span class="c1"># Free sound effect model
</span>    <span class="k">del</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="s">"audio_medium"</span><span class="p">]</span>
    <span class="n">gc</span><span class="p">.</span><span class="n">collect</span><span class="p">()</span>
    
    <span class="c1"># Final stage: Mix everything
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"Final stage: Assembling and mixing..."</span><span class="p">)</span>
    <span class="c1"># [Implementation would assemble all generated audio files]
</span></code></pre></div></div>

<h2 id="hands-on-challenge">Hands-on Challenge</h2>

<p>Now it’s your turn to experiment with what you’ve learned. Try the following challenge:</p>

<h3 id="challenge-interactive-storytelling-system">Challenge: Interactive Storytelling System</h3>

<p>Create an interactive storytelling system that:</p>
<ol>
  <li>Takes a story script with branching narrative options</li>
  <li>Generates audio for all possible narrative paths</li>
  <li>Provides an interface for making choices at decision points</li>
  <li>Seamlessly transitions between narrative segments based on choices</li>
  <li>Includes dynamic background music that adapts to the story context</li>
</ol>

<h3 id="bonus-challenge">Bonus Challenge</h3>

<p>Implement an emotion analysis system that identifies the emotional tone of text and automatically selects appropriate background music and sound effects based on the detected emotion.</p>

<h2 id="key-takeaways">Key Takeaways</h2>

<ul>
  <li>Modern TTS systems can be effectively integrated with AudioCraft to create complete audio experiences</li>
  <li>A unified pipeline architecture simplifies the creation of complex audio narratives</li>
  <li>Timeline-based composition enables precise control over audio elements</li>
  <li>Memory management is crucial when working with multiple generative models</li>
  <li>Emotion and context awareness enhance the realism and impact of audio narratives</li>
</ul>

<h2 id="next-steps">Next Steps</h2>

<p>Now that you’ve mastered TTS integration with AudioCraft, you’re ready to explore:</p>

<ul>
  <li><strong>Interactive Audio Systems</strong>: Build responsive audio experiences that adapt to user input and context</li>
  <li><strong>Real-time Generation</strong>: Explore techniques for generating audio on-demand with minimal latency</li>
  <li><strong>Multi-modal Integration</strong>: Combine audio generation with other AI modalities like image and video</li>
</ul>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://github.com/suno-ai/bark">Bark TTS GitHub Repository</a> - Expressive text-to-speech system</li>
  <li><a href="https://docs.elevenlabs.io/">ElevenLabs Documentation</a> - Advanced voice synthesis platform</li>
  <li><a href="https://www.w3.org/TR/speech-synthesis11/">SSML Specification</a> - Speech Synthesis Markup Language standard</li>
  <li><a href="https://github.com/facebookresearch/audiocraft">AudioCraft Documentation</a> - Official documentation for Meta’s audio generation tools</li>
  <li><a href="https://www.soundonsound.com/techniques">Audio Production Techniques</a> - Professional audio mixing and production guides</li>
</ul>

  
  
  
  
  
  
  
  
</div>

<div class="chapter-navigation">
  
  <a href="/chapters/part5/research-extensions-future-directions/" class="prev-chapter">
    <span class="nav-label">Previous</span>
    <span class="nav-title">Chapter 21: Research Extensions and Future Directions</span>
  </a>
  
  
  
</div>

<!-- Copyright footer for all chapter pages -->
<div class="copyright-footer">
  <hr>
  <p>
    Copyright © 2025 Scott Friedman.
    <br>
    This work is licensed under the <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.
  </p>
</div>


        </div>
      </main>

      <footer class="site-footer">
        <div class="container">
          <div class="footer-col-wrapper">
            <div class="footer-col">
              <p>A hands-on guide to creating music, sound effects, and audio experiences with AI</p>
              <p>
                <a href="https://github.com/facebookresearch/audiocraft">AudioCraft GitHub Repository</a>
              </p>
            </div>
            <div class="footer-col">
              <p class="copyright">
                Copyright © 2025 Scott Friedman.<br>
                Licensed under <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a>.
              </p>
            </div>
          </div>
        </div>
      </footer>
    </div>
  </body>
</html>